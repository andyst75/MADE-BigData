# Домашнее задание №5

## Линейная регрессия breeze + spark ml


В рамках домашнего задания было создано 2 класса.

LinearRegression производит обучением методом градиентного спуска на полном наборе данных.

LinearRegressionBatch производит матричные вычисления, беря на каждом шаге обучения подвыборку из набора данных.

Результат обучения модели до уровня ошибки ниже 10<sup>-14</sup>.


    Start train LinearRegression
    Epoch=001 slope=(1.494249818403868, 0.28605473429917505, -0.7047182317942156) intercept=0.000852 loss=-0.00085238
    Epoch=002 slope=(1.4998738065753452, 0.29984055707726853, -0.699980856747331) intercept=0.000003 loss=0.00084940
    Epoch=003 slope=(1.4999984527661585, 0.2999977185038916, -0.7000002056702794) intercept=0.000000 loss=0.00000294
    Epoch=004 slope=(1.4999999782278812, 0.2999999692799901, -0.7000000002171222) intercept=0.000000 loss=0.00000004
    Epoch=005 slope=(1.4999999997059121, 0.29999999957952067, -0.7000000000172251) intercept=0.000000 loss=0.00000000
    Epoch=006 slope=(1.4999999999959768, 0.2999999999942725, -0.7000000000001565) intercept=0.000000 loss=0.00000000
    Epoch=007 slope=(1.4999999999999452, 0.29999999999992183, -0.7000000000000025) intercept=0.000000 loss=0.00000000
    Epoch=008 slope=(1.4999999999999993, 0.29999999999999893, -0.7) intercept=0.000000 loss=0.00000000


    Start train LinearRegression with batches
    Epoch=001 slope=(1.4999999999999982, 0.3, -0.7000000000000001) intercept=-0.000000 loss=0.00000000
    Epoch=002 slope=(1.5000000000000013, 0.2999999999999998, -0.6999999999999997) intercept=-0.000000 loss=0.00000000
    Epoch=003 slope=(1.4999999999999996, 0.2999999999999998, -0.6999999999999998) intercept=-0.000000 loss=0.00000000
    Epoch=004 slope=(1.5000000000000004, 0.30000000000000004, -0.6999999999999997) intercept=-0.000000 loss=0.00000000
    Epoch=005 slope=(1.5000000000000013, 0.3000000000000002, -0.7) intercept=0.000000 loss=0.00000000
    Epoch=006 slope=(1.5000000000000024, 0.29999999999999993, -0.7) intercept=0.000000 loss=-0.00000000

